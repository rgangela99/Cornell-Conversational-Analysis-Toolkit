{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename='long-reddit-corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_str = lambda s: clean(s,\n",
    "                            fix_unicode=True,               # fix various unicode errors\n",
    "                            to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "                            lower=True,                     # lowercase text\n",
    "                            no_line_breaks=True,           # fully strip line breaks as opposed to only normalizing them\n",
    "                            no_urls=True,                  # replace all URLs with a special token\n",
    "                            no_emails=True,                # replace all email addresses with a special token\n",
    "                            no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "                            no_numbers=False,               # replace all numbers with a special token\n",
    "                            no_digits=False,                # replace all digits with a special token\n",
    "                            no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "                            no_punct=False,                 # fully remove punctuation\n",
    "                            replace_with_url=\"<URL>\",\n",
    "                            replace_with_email=\"<EMAIL>\",\n",
    "                            replace_with_phone_number=\"<PHONE>\",\n",
    "                            replace_with_number=\"<NUMBER>\",\n",
    "                            replace_with_digit=\"0\",\n",
    "                            replace_with_currency_symbol=\"<CUR>\",\n",
    "                            lang=\"en\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCleaner(text_cleaner=clean_str, verbosity=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/1085877 utterances processed\n",
      "200000/1085877 utterances processed\n",
      "300000/1085877 utterances processed\n",
      "400000/1085877 utterances processed\n",
      "500000/1085877 utterances processed\n",
      "600000/1085877 utterances processed\n",
      "700000/1085877 utterances processed\n",
      "800000/1085877 utterances processed\n",
      "900000/1085877 utterances processed\n",
      "1000000/1085877 utterances processed\n",
      "1085877/1085877 utterances processed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x1284fa990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt = corpus.random_utterance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if you haven't listened to breaking all illusions off of adtoe you should check it out. one of the best songs they've ever released i agree that there's a lot of 'filler' from their recent albums though\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if you haven't listened to breaking all illusions off of ADTOE you should check it out. one of the best songs they've ever released\\n\\ni agree that there's a lot of 'filler' from their recent albums though\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utt.meta['original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "utt_ids = []\n",
    "utt_texts = []\n",
    "\n",
    "for convo in corpus.iter_conversations():\n",
    "    for utt in convo.get_chronological_utterance_list()[:20]:\n",
    "        utt_ids.append(utt.id)\n",
    "        utt_texts.append(utt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589740"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([utt_ids, utt_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df[0]\n",
    "df['text'] = df[1]\n",
    "del df[0]\n",
    "del df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('utts.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after liwc processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('utts_liwc.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('Source (B)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Source (A)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Source (C)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in df.iterrows():\n",
    "    utt_id = r[0]\n",
    "    feats = r[1].to_dict()\n",
    "    corpus.get_utterance(utt_id).meta['liwc'] = feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.dump('long-reddit-corpus-liwc', base_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'utts.xlsx',\n",
       " 'liwc_annotation.ipynb',\n",
       " 'long-reddit-corpus',\n",
       " 'quick_stats.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'utts_liwc.xlsx',\n",
       " '~$utts_liwc.xlsx']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do yourself a favor and make it the last time you step into \"any\" church. great story though, goes to show the insincerity and true nature of these so called church leaders.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_utterance('dnxhx8v').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dnxhx8v'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dnxhx8v', WC              32.00\n",
      "Analytic        64.83\n",
      "Clout           96.95\n",
      "Authentic       35.37\n",
      "Tone            99.00\n",
      "WPS             16.00\n",
      "Sixltr           9.38\n",
      "Dic             96.88\n",
      "function        46.88\n",
      "pronoun         12.50\n",
      "ppron            6.25\n",
      "i                0.00\n",
      "we               0.00\n",
      "you              6.25\n",
      "shehe            0.00\n",
      "they             0.00\n",
      "ipron            6.25\n",
      "article          9.38\n",
      "prep             9.38\n",
      "auxverb          3.12\n",
      "adverb           6.25\n",
      "conj            12.50\n",
      "negate           0.00\n",
      "verb            12.50\n",
      "adj              6.25\n",
      "compare          0.00\n",
      "interrog         0.00\n",
      "number           0.00\n",
      "quant            3.12\n",
      "affect          12.50\n",
      "                ...  \n",
      "focuspresent     9.38\n",
      "focusfuture      0.00\n",
      "relativ         15.62\n",
      "motion           6.25\n",
      "space            3.12\n",
      "time             6.25\n",
      "work             3.12\n",
      "leisure          0.00\n",
      "home             0.00\n",
      "money            0.00\n",
      "relig            6.25\n",
      "death            0.00\n",
      "informal         0.00\n",
      "swear            0.00\n",
      "netspeak         0.00\n",
      "assent           0.00\n",
      "nonflu           0.00\n",
      "filler           0.00\n",
      "AllPunc         15.62\n",
      "Period           6.25\n",
      "Comma            3.12\n",
      "Colon            0.00\n",
      "SemiC            0.00\n",
      "QMark            0.00\n",
      "Exclam           0.00\n",
      "Dash             0.00\n",
      "Quote            6.25\n",
      "Apostro          0.00\n",
      "Parenth          0.00\n",
      "OtherP           0.00\n",
      "Name: dnxhx8v, Length: 93, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "for r in df.iterrows():\n",
    "    print(r)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIWC matrix construction for each conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a matrix containing the LIWC feats for the first 20 utts of each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename='long-reddit-corpus-liwc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.random_utterance().meta['liwc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in corpus.iter_conversations():\n",
    "    utts_20 = convo.get_chronological_utterance_list()[:20]\n",
    "    mat = np.zeros((20, 93))\n",
    "    for idx, utt in enumerate(convo.get_chronological_utterance_list()[:20]):\n",
    "        mat[idx] = np.array(list(utt.meta['liwc'].values()))\n",
    "    convo.meta['liwc'] = mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.dump('long-reddit-corpus-liwc', base_path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
