{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('convokit/tensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename='reddit-corpus-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import HyperConvo, Hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HyperConvo(prefix_len=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x12a5e74d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = corpus.random_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhiteHawk928\n",
      "    PsychicStardust\n",
      "        shamrock-frost\n",
      "            PsychicStardust\n",
      "                shamrock-frost\n",
      "                    chaingunXD\n",
      "                        javilla\n",
      "                            MTGCardFetcher\n",
      "                        Alucart333\n",
      "                    PsychicStardust\n",
      "        Quazifuji\n",
      "        Merosi\n",
      "            PsychicStardust\n",
      "        torolf_212\n"
     ]
    }
   ],
   "source": [
    "convo.print_conversation_structure(limit=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Hypergraph.init_from_utterances(utterances=convo.get_chronological_utterance_list()[:15])\n",
    "stats = {}\n",
    "for k, v in HyperConvo._degree_feats(graph=G).items(): stats[k] = v\n",
    "for k, v in HyperConvo._motif_feats(graph=G).items(): stats[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max[indegree over c->c responses]': 4,\n",
       " 'argmax[indegree over c->c responses]': 1,\n",
       " 'norm.max[indegree over c->c responses]': 0.3076923076923077,\n",
       " '2nd-largest[indegree over c->c responses]': 2,\n",
       " '2nd-argmax[indegree over c->c responses]': 4,\n",
       " 'norm.2nd-largest[indegree over c->c responses]': 0.15384615384615385,\n",
       " 'mean[indegree over c->c responses]': 0.9285714285714286,\n",
       " 'mean-nonzero[indegree over c->c responses]': 1.625,\n",
       " 'prop-nonzero[indegree over c->c responses]': 0.5714285714285714,\n",
       " 'prop-multiple[indegree over c->c responses]': 0.375,\n",
       " 'entropy[indegree over c->c responses]': 1.9251211907908183,\n",
       " '2nd-largest / max[indegree over c->c responses]': 0.5,\n",
       " 'max[outdegree over C->c responses]': 4,\n",
       " 'max[indegree over C->c responses]': 4,\n",
       " 'argmax[outdegree over C->c responses]': 1,\n",
       " 'argmax[indegree over C->c responses]': 1,\n",
       " 'norm.max[outdegree over C->c responses]': 0.3076923076923077,\n",
       " 'norm.max[indegree over C->c responses]': 0.3076923076923077,\n",
       " '2nd-largest[outdegree over C->c responses]': 2,\n",
       " '2nd-largest[indegree over C->c responses]': 2,\n",
       " '2nd-argmax[outdegree over C->c responses]': 2,\n",
       " '2nd-argmax[indegree over C->c responses]': 4,\n",
       " 'norm.2nd-largest[outdegree over C->c responses]': 0.15384615384615385,\n",
       " 'norm.2nd-largest[indegree over C->c responses]': 0.15384615384615385,\n",
       " 'mean[outdegree over C->c responses]': 1.3,\n",
       " 'mean[indegree over C->c responses]': 0.9285714285714286,\n",
       " 'mean-nonzero[outdegree over C->c responses]': 1.4444444444444444,\n",
       " 'mean-nonzero[indegree over C->c responses]': 1.625,\n",
       " 'prop-nonzero[outdegree over C->c responses]': 0.9,\n",
       " 'prop-nonzero[indegree over C->c responses]': 0.5714285714285714,\n",
       " 'prop-multiple[outdegree over C->c responses]': 0.2222222222222222,\n",
       " 'prop-multiple[indegree over C->c responses]': 0.375,\n",
       " 'entropy[outdegree over C->c responses]': 2.031759218569271,\n",
       " 'entropy[indegree over C->c responses]': 1.9251211907908183,\n",
       " '2nd-largest / max[outdegree over C->c responses]': 0.5,\n",
       " '2nd-largest / max[indegree over C->c responses]': 0.5,\n",
       " 'max[outdegree over C->C responses]': 3,\n",
       " 'max[indegree over C->C responses]': 4,\n",
       " 'argmax[outdegree over C->C responses]': 1,\n",
       " 'argmax[indegree over C->C responses]': 1,\n",
       " 'norm.max[outdegree over C->C responses]': 0.2727272727272727,\n",
       " 'norm.max[indegree over C->C responses]': 0.36363636363636365,\n",
       " '2nd-largest[outdegree over C->C responses]': 1,\n",
       " '2nd-largest[indegree over C->C responses]': 2,\n",
       " '2nd-argmax[outdegree over C->C responses]': 2,\n",
       " '2nd-argmax[indegree over C->C responses]': 2,\n",
       " 'norm.2nd-largest[outdegree over C->C responses]': 0.09090909090909091,\n",
       " 'norm.2nd-largest[indegree over C->C responses]': 0.18181818181818182,\n",
       " 'mean[outdegree over C->C responses]': 1.1,\n",
       " 'mean[indegree over C->C responses]': 1.1,\n",
       " 'mean-nonzero[outdegree over C->C responses]': 1.2222222222222223,\n",
       " 'mean-nonzero[indegree over C->C responses]': 1.8333333333333333,\n",
       " 'prop-nonzero[outdegree over C->C responses]': 0.9,\n",
       " 'prop-nonzero[indegree over C->C responses]': 0.6,\n",
       " 'prop-multiple[outdegree over C->C responses]': 0.1111111111111111,\n",
       " 'prop-multiple[indegree over C->C responses]': 0.5,\n",
       " 'entropy[outdegree over C->C responses]': 2.0982737395252498,\n",
       " 'entropy[indegree over C->C responses]': 1.6417347121875214,\n",
       " '2nd-largest / max[outdegree over C->C responses]': 0.3333333333333333,\n",
       " '2nd-largest / max[indegree over C->C responses]': 0.5,\n",
       " 'is-present[reciprocity motif]': True,\n",
       " 'count[reciprocity motif]': 4,\n",
       " 'is-present[external reciprocity motif]': True,\n",
       " 'count[external reciprocity motif]': 8,\n",
       " 'is-present[dyadic interaction motif]': True,\n",
       " 'count[dyadic interaction motif]': 2,\n",
       " 'is-present[incoming triads]': True,\n",
       " 'count[incoming triads]': 8,\n",
       " 'is-present[outgoing triads]': True,\n",
       " 'count[outgoing triads]': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "in [0 0 0 0 0 0]\n",
      "True False\n",
      "out [0 0 0 0 0 0]\n",
      "in [0 0 0 0 0 0]\n",
      "True True\n",
      "out [0 0 0 0 0 0]\n",
      "in [0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "graph = Hypergraph.init_from_utterances(utterances=convo.get_chronological_utterance_list()[1:7])\n",
    "\n",
    "stats = {}\n",
    "for from_hyper in [False, True]:\n",
    "    for to_hyper in [False, True]:\n",
    "        if not from_hyper and to_hyper: continue # skip c->C\n",
    "        print(from_hyper, to_hyper)\n",
    "        if from_hyper:\n",
    "            outdegrees = np.array(graph.outdegrees(from_hyper, to_hyper))\n",
    "            print(\"out\", outdegrees)\n",
    "        indegrees = np.array(graph.indegrees(from_hyper, to_hyper))\n",
    "        \n",
    "        print(\"in\", indegrees)\n",
    "#         for stat, stat_func in degree_stat_funcs.items():\n",
    "#             if from_hyper:\n",
    "#                 stats[\"{}[outdegree over {}->{} {}responses]\".format(stat,\n",
    "#                                                              HyperConvo._node_type_name(from_hyper),\n",
    "#                                                              HyperConvo._node_type_name(to_hyper),\n",
    "#                                                              name_ext)] = stat_func(outdegrees)\n",
    "\n",
    "#             stats[\"{}[indegree over {}->{} {}responses]\".format(stat,\n",
    "#                                                                 HyperConvo._node_type_name(from_hyper),\n",
    "#                                                                 HyperConvo._node_type_name(to_hyper),\n",
    "#                                                                 name_ext)] = stat_func(indegrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "degree_stat_funcs = {\n",
    "    \"max\": np.max,\n",
    "    \"argmax\": np.argmax,\n",
    "    \"norm.max\": lambda l: np.max(l) / np.sum(l) if np.sum(l) > 0 else 0,\n",
    "    \"2nd-largest\": lambda l: np.partition(l, -2)[-2] if len(l) > 1 else np.nan,\n",
    "    \"2nd-argmax\": lambda l: (-l).argsort()[1] if len(l) > 1 else np.nan,\n",
    "    \"norm.2nd-largest\": lambda l: np.partition(l, -2)[-2] / np.sum(l) if (len(l) > 1 and np.sum(l) > 0) else np.nan,\n",
    "    \"mean\": np.mean,\n",
    "    \"mean-nonzero\": lambda l: np.mean(l[l != 0]) if len(l[l != 0]) > 0 else 0,\n",
    "    \"prop-nonzero\": lambda l: np.mean(l != 0),\n",
    "    \"prop-multiple\": lambda l: np.mean(l[l != 0] > 1) if len(l[l !=0] > 1) > 0 else 0,\n",
    "    \"entropy\": lambda l: scipy.stats.entropy(l) if np.sum(l) > 0 else np.nan,\n",
    "    \"2nd-largest / max\": lambda l: np.partition(l, -2)[-2] / np.max(l) if (len(l) > 1 and np.sum(l) > 0) else np.nan\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "indegrees[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stat, func in degree_stat_funcs.items():\n",
    "    func(indegrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeWarning",
     "evalue": "invalid value encountered in long_scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeWarning\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-fd73093c6d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mG_mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHypergraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_utterances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chronological_utterance_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mHyperConvo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_degree_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mG_mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_ext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mid-thread \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# for k, v in HyperConvo._motif_feats(graph=G_mid, name_ext=\" over mid-thread\").items(): stats[k] = v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py\u001b[0m in \u001b[0;36m_degree_feats\u001b[0;34m(graph, name_ext)\u001b[0m\n\u001b[1;32m    134\u001b[0m                                                                         \u001b[0mHyperConvo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_hyper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                                                                         \u001b[0mHyperConvo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_hyper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                                                                         name_ext)] = stat_func(indegrees)\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo/hyperconvo.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"argmax\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;34m\"norm.max\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"2nd-largest\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"2nd-argmax\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeWarning\u001b[0m: invalid value encountered in long_scalars"
     ]
    }
   ],
   "source": [
    "G_mid = Hypergraph.init_from_utterances(utterances=convo.get_chronological_utterance_list()[1:7])\n",
    "\n",
    "\n",
    "for k, v in HyperConvo._degree_feats(graph=G_mid, name_ext=\"mid-thread \").items(): stats[k] = v\n",
    "# for k, v in HyperConvo._motif_feats(graph=G_mid, name_ext=\" over mid-thread\").items(): stats[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = corpus.random_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HyperConvo()\n",
    "hc.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.print_conversation_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(convo.meta['hyperconvo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.meta['hyperconvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.print_conversation_structure(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import HyperConvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HyperConvo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc.transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = a.random_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.meta['hyperconvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = a.random_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = list(convo.meta['hyperconvo'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_to_c_feats = [feat for feat in feats if 'c->c' in feat and 'mid-thread' not in feat]\n",
    "C_to_c_feats = [feat for feat in feats if 'C->c' in feat and 'mid-thread' not in feat]\n",
    "C_to_C_feats = [feat for feat in feats if 'C->C' in feat and 'mid-thread' not in feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_to_c_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_to_C_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vals(convo):\n",
    "    feat_vals = convo.meta['hyperconvo']\n",
    "    c_to_c = np.array([feat_vals[k] for k in c_to_c_feats])\n",
    "    C_to_c = np.array([feat_vals[k] for k in C_to_c_feats])\n",
    "    C_to_C = np.array([feat_vals[k] for k in C_to_C_feats])\n",
    "    return c_to_c, C_to_c, C_to_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_feats(convo):\n",
    "    c2c, C2c, C2C = get_feature_vals(convo)\n",
    "    return np.all(c2c == C2c), np.all(C2c == C2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo1 = a.random_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo1.meta['hyperconvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo2 = a.random_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2, c3 = get_feature_vals(convo1)\n",
    "c1_, c2_, c3_ = get_feature_vals(convo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2c_out = [k for k in c_to_c_feats if 'out' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c2c(convo):\n",
    "    feat_vals = convo.meta['hyperconvo']\n",
    "    c_to_c = np.array([feat_vals[k] for k in c2c_out])\n",
    "    return c_to_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_c2c(convo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_c2c(convo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2c_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in a.iter_conversations():\n",
    "    print(np.all(get_c2c(convo) == m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_to_c_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in a.iter_conversations():\n",
    "    print(compare_feats(convo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_vals(convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.print_conversation_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_features = a.random_conversation().meta['hyperconvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.print_conversatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for convo in a.iter_conversations():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
