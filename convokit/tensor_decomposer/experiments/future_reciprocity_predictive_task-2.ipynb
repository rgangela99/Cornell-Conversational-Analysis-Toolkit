{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, HyperConvo, TensorDecomposer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we download the reddit corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = Corpus(filename=\"convokit/thread_generator/fake-corpus-trajectory-40\")\n",
    "corpus = Corpus(filename=\"convokit/thread_generator/annotated-fake-trajectory-experiment-2\")\n",
    "# corpus = Corpus(filename=\"convokit/tensor_decomposer/experiments/reddit-trajectory-subset-annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 40\n",
      "Number of Utterances: 75000\n",
      "Number of Conversations: 3000\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperconv_range = range(2, 20+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grown = 0\n",
    "thresh = 1.5\n",
    "for convo in corpus.iter_conversations():\n",
    "    try:\n",
    "        recip_div = convo.meta['hyperconvo-25']['count[reciprocity motif]'] / convo.meta['hyperconvo-20']['count[reciprocity motif]']\n",
    "    except ZeroDivisionError:\n",
    "        if convo.meta['hyperconvo-20']['count[reciprocity motif]'] == 0:\n",
    "            recip_div = 0\n",
    "        else:\n",
    "            recip_div = 10\n",
    "    convo.meta['grown'] = recip_div >= thresh\n",
    "    grown += convo.meta['grown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grown2 = 0\n",
    "thresh = 3.0\n",
    "for convo in corpus.iter_conversations():\n",
    "    recip_diff = convo.meta['hyperconvo-25']['count[reciprocity motif]'] - convo.meta['hyperconvo-20']['count[reciprocity motif]']\n",
    "    convo.meta['grown2'] = recip_diff >= thresh\n",
    "    grown2 += convo.meta['grown2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grown2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Classifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = Classifier(obj_type=\"conversation\", pred_feats=['hyperconvo-20'], labeller=lambda convo: convo.meta['grown'],\n",
    "#                 clf_feat_name='hyperconv-pred', clf_prob_feat_name='hyperconv-pred-score'\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(obj_type=\"conversation\", pred_feats=['hyperconvo-20'], labeller=lambda convo: convo.meta['grown'],\n",
    "                clf_feat_name='hyperconv-pred', clf_prob_feat_name='hyperconv-pred-score'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "res = clf.evaluate_with_cv(corpus, cv=KFold(n_splits=5, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.classifier.classifier.Classifier at 0x131274f90>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is-present[reciprocity motif]</th>\n",
       "      <td>0.308368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is-present[dyadic interaction motif]</th>\n",
       "      <td>0.288368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max[indegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>0.218516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count[reciprocity motif over mid-thread]</th>\n",
       "      <td>0.210676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-nonzero[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>0.151885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-nonzero[outdegree over C-&gt;C responses]</th>\n",
       "      <td>0.118984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max[outdegree over C-&gt;c responses]</th>\n",
       "      <td>0.110646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is-present[reciprocity motif over mid-thread]</th>\n",
       "      <td>0.109935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is-present[dyadic interaction motif over mid-thread]</th>\n",
       "      <td>0.109935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argmax[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>0.109028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-nonzero[indegree over C-&gt;C responses]</th>\n",
       "      <td>0.104753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-nonzero[outdegree over C-&gt;c responses]</th>\n",
       "      <td>0.085632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-nonzero[indegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>0.085243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>0.082413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean[outdegree over C-&gt;C responses]</th>\n",
       "      <td>0.076009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean[indegree over C-&gt;C responses]</th>\n",
       "      <td>0.076009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-nonzero[outdegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>0.072590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-argmax[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>0.072036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[outdegree over C-&gt;C responses]</th>\n",
       "      <td>0.067296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argmax[outdegree over C-&gt;c responses]</th>\n",
       "      <td>0.060194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is-present[outgoing triads over mid-thread]</th>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count[external reciprocity motif]</th>\n",
       "      <td>0.055743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>0.052692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[outdegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>0.052103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-argmax[outdegree over C-&gt;c responses]</th>\n",
       "      <td>0.045231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest[indegree over c-&gt;c mid-thread responses]</th>\n",
       "      <td>0.043720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest[indegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>0.043720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count[reciprocity motif]</th>\n",
       "      <td>0.040031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean[outdegree over C-&gt;c responses]</th>\n",
       "      <td>0.038373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy[indegree over c-&gt;c mid-thread responses]</th>\n",
       "      <td>0.037593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest / max[indegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>-0.019892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-nonzero[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>-0.022996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-nonzero[outdegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.022996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest[indegree over C-&gt;C responses]</th>\n",
       "      <td>-0.024026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest / max[outdegree over C-&gt;C responses]</th>\n",
       "      <td>-0.025899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is-present[incoming triads over mid-thread]</th>\n",
       "      <td>-0.033395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest[indegree over c-&gt;c responses]</th>\n",
       "      <td>-0.035101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest[indegree over C-&gt;c responses]</th>\n",
       "      <td>-0.035101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max[outdegree over C-&gt;C responses]</th>\n",
       "      <td>-0.035818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count[external reciprocity motif over mid-thread]</th>\n",
       "      <td>-0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argmax[outdegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.053494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy[outdegree over C-&gt;C responses]</th>\n",
       "      <td>-0.053599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argmax[indegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.054840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[indegree over C-&gt;c responses]</th>\n",
       "      <td>-0.058731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[indegree over c-&gt;c responses]</th>\n",
       "      <td>-0.058731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[indegree over c-&gt;c mid-thread responses]</th>\n",
       "      <td>-0.060332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[indegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>-0.060332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean-nonzero[indegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.069273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>argmax[indegree over C-&gt;C responses]</th>\n",
       "      <td>-0.069396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest / max[indegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.078478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest / max[outdegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.079927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count[incoming triads over mid-thread]</th>\n",
       "      <td>-0.083149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy[outdegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.087563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy[outdegree over C-&gt;c responses]</th>\n",
       "      <td>-0.093913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>-0.104107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[indegree over C-&gt;C mid-thread responses]</th>\n",
       "      <td>-0.106813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prop-multiple[indegree over C-&gt;C responses]</th>\n",
       "      <td>-0.121402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd-largest[outdegree over C-&gt;c mid-thread responses]</th>\n",
       "      <td>-0.122730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max[indegree over C-&gt;C responses]</th>\n",
       "      <td>-0.144996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count[dyadic interaction motif over mid-thread]</th>\n",
       "      <td>-0.215150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        coef\n",
       "feat_name                                                   \n",
       "is-present[reciprocity motif]                       0.308368\n",
       "is-present[dyadic interaction motif]                0.288368\n",
       "max[indegree over C->C mid-thread responses]        0.218516\n",
       "count[reciprocity motif over mid-thread]            0.210676\n",
       "mean-nonzero[outdegree over C->c mid-thread res...  0.151885\n",
       "mean-nonzero[outdegree over C->C responses]         0.118984\n",
       "max[outdegree over C->c responses]                  0.110646\n",
       "is-present[reciprocity motif over mid-thread]       0.109935\n",
       "is-present[dyadic interaction motif over mid-th...  0.109935\n",
       "argmax[outdegree over C->c mid-thread responses]    0.109028\n",
       "prop-nonzero[indegree over C->C responses]          0.104753\n",
       "mean-nonzero[outdegree over C->c responses]         0.085632\n",
       "prop-nonzero[indegree over C->C mid-thread resp...  0.085243\n",
       "prop-multiple[outdegree over C->c mid-thread re...  0.082413\n",
       "mean[outdegree over C->C responses]                 0.076009\n",
       "mean[indegree over C->C responses]                  0.076009\n",
       "mean-nonzero[outdegree over C->C mid-thread res...  0.072590\n",
       "2nd-argmax[outdegree over C->c mid-thread respo...  0.072036\n",
       "prop-multiple[outdegree over C->C responses]        0.067296\n",
       "argmax[outdegree over C->c responses]               0.060194\n",
       "is-present[outgoing triads over mid-thread]         0.060000\n",
       "count[external reciprocity motif]                   0.055743\n",
       "max[outdegree over C->c mid-thread responses]       0.052692\n",
       "prop-multiple[outdegree over C->C mid-thread re...  0.052103\n",
       "2nd-argmax[outdegree over C->c responses]           0.045231\n",
       "2nd-largest[indegree over c->c mid-thread respo...  0.043720\n",
       "2nd-largest[indegree over C->c mid-thread respo...  0.043720\n",
       "count[reciprocity motif]                            0.040031\n",
       "mean[outdegree over C->c responses]                 0.038373\n",
       "entropy[indegree over c->c mid-thread responses]    0.037593\n",
       "...                                                      ...\n",
       "2nd-largest / max[indegree over C->c mid-thread... -0.019892\n",
       "prop-nonzero[outdegree over C->c mid-thread res... -0.022996\n",
       "prop-nonzero[outdegree over C->C mid-thread res... -0.022996\n",
       "2nd-largest[indegree over C->C responses]          -0.024026\n",
       "2nd-largest / max[outdegree over C->C responses]   -0.025899\n",
       "is-present[incoming triads over mid-thread]        -0.033395\n",
       "2nd-largest[indegree over c->c responses]          -0.035101\n",
       "2nd-largest[indegree over C->c responses]          -0.035101\n",
       "max[outdegree over C->C responses]                 -0.035818\n",
       "count[external reciprocity motif over mid-thread]  -0.042644\n",
       "argmax[outdegree over C->C mid-thread responses]   -0.053494\n",
       "entropy[outdegree over C->C responses]             -0.053599\n",
       "argmax[indegree over C->C mid-thread responses]    -0.054840\n",
       "prop-multiple[indegree over C->c responses]        -0.058731\n",
       "prop-multiple[indegree over c->c responses]        -0.058731\n",
       "prop-multiple[indegree over c->c mid-thread res... -0.060332\n",
       "prop-multiple[indegree over C->c mid-thread res... -0.060332\n",
       "mean-nonzero[indegree over C->C mid-thread resp... -0.069273\n",
       "argmax[indegree over C->C responses]               -0.069396\n",
       "2nd-largest / max[indegree over C->C mid-thread... -0.078478\n",
       "2nd-largest / max[outdegree over C->C mid-threa... -0.079927\n",
       "count[incoming triads over mid-thread]             -0.083149\n",
       "entropy[outdegree over C->C mid-thread responses]  -0.087563\n",
       "entropy[outdegree over C->c responses]             -0.093913\n",
       "entropy[outdegree over C->c mid-thread responses]  -0.104107\n",
       "prop-multiple[indegree over C->C mid-thread res... -0.106813\n",
       "prop-multiple[indegree over C->C responses]        -0.121402\n",
       "2nd-largest[outdegree over C->c mid-thread resp... -0.122730\n",
       "max[indegree over C->C responses]                  -0.144996\n",
       "count[dyadic interaction motif over mid-thread]    -0.215150\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_feats = list(corpus.random_conversation().meta['hyperconvo-20'])\n",
    "clf.get_coefs(clf_feats, lambda model: model.coef_.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8973333333333333"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor feats (rank 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TensorDecomposer(obj_type=\"conversation\",\n",
    "                      feature_set=[\"hyperconvo-{}\".format(i) for i in range(2, 21)],\n",
    "                      group_func=lambda convo: convo.get_utterance(convo.id).meta['subreddit'],\n",
    "                      rank=3, tensor_func='tensortools-ncp-hals'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tensor...Done.\n",
      "Decomposing tensor...NCP_HALS: iteration 1, objective 0.4705557696201128, improvement inf.\n",
      "NCP_HALS: iteration 2, objective 0.38718167779788215, improvement 0.08337409182223066.\n",
      "NCP_HALS: iteration 3, objective 0.37909679479507163, improvement 0.008084883002810517.\n",
      "NCP_HALS: iteration 4, objective 0.3756453415165847, improvement 0.003451453278486949.\n",
      "NCP_HALS: iteration 5, objective 0.37381467358895404, improvement 0.001830667927630647.\n",
      "NCP_HALS: iteration 6, objective 0.37286048661276505, improvement 0.0009541869761889865.\n",
      "NCP_HALS: iteration 7, objective 0.37233013239138185, improvement 0.0005303542213832002.\n",
      "NCP_HALS: iteration 8, objective 0.37202999361193284, improvement 0.0003001387794490107.\n",
      "NCP_HALS: iteration 9, objective 0.37186436976239035, improvement 0.00016562384954249554.\n",
      "NCP_HALS: iteration 10, objective 0.3717697571236038, improvement 9.461263878657311e-05.\n",
      "NCP_HALS: iteration 11, objective 0.37171019342378886, improvement 5.956369981491294e-05.\n",
      "NCP_HALS: iteration 12, objective 0.37166782114735236, improvement 4.237227643649755e-05.\n",
      "NCP_HALS: iteration 13, objective 0.37163452837886835, improvement 3.3292768484016744e-05.\n",
      "NCP_HALS: iteration 14, objective 0.37160670012752045, improvement 2.782825134789446e-05.\n",
      "NCP_HALS: iteration 15, objective 0.37158237133371347, improvement 2.4328793806982496e-05.\n",
      "NCP_HALS: iteration 16, objective 0.37156053996006116, improvement 2.1831373652303476e-05.\n",
      "NCP_HALS: iteration 17, objective 0.3715405612413983, improvement 1.9978718662883033e-05.\n",
      "NCP_HALS: iteration 18, objective 0.37152207109517105, improvement 1.849014622723466e-05.\n",
      "NCP_HALS: iteration 19, objective 0.3715047927855952, improvement 1.7278309575874395e-05.\n",
      "NCP_HALS: iteration 20, objective 0.37148850956973495, improvement 1.628321586022441e-05.\n",
      "NCP_HALS: iteration 21, objective 0.3714731905050632, improvement 1.5319064671726057e-05.\n",
      "NCP_HALS: iteration 22, objective 0.37145918778762227, improvement 1.4002717440952939e-05.\n",
      "NCP_HALS: iteration 23, objective 0.3714464642991604, improvement 1.2723488461874322e-05.\n",
      "NCP_HALS: iteration 24, objective 0.3714348259362987, improvement 1.1638362861721152e-05.\n",
      "NCP_HALS: iteration 25, objective 0.37142412070545533, improvement 1.0705230843344182e-05.\n",
      "NCP_HALS: iteration 26, objective 0.37141424096234243, improvement 9.879743112894968e-06.\n",
      "Converged after 26 iterations, 1.5115334620000027 seconds. Objective: 0.37141424096234243.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.tensor_decomposer.tensorDecomposer.TensorDecomposer at 0x127e94210>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x127e8c690>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import BoWClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing default classification model (standard scaled logistic regression)\n"
     ]
    }
   ],
   "source": [
    "clf_tensor = BoWClassifier(obj_type=\"conversation\", vector_name='tensor_factor', \n",
    "                           labeller=lambda convo: convo.meta['grown2'],\n",
    "                clf_feat_name='tensor-pred', clf_prob_feat_name='tensor-pred-score'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "res = clf_tensor.evaluate_with_cv(corpus, cv=KFold(n_splits=5, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7183333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in corpus.iter_conversations():\n",
    "    convo.meta['tensor_rank3'] = convo.meta['tensor_factor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank 9 decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_9 = TensorDecomposer(obj_type=\"conversation\",\n",
    "                      feature_set=[\"hyperconvo-{}\".format(i) for i in range(2, 21)],\n",
    "                      group_func=lambda convo: convo.get_utterance(convo.id).meta['subreddit'],\n",
    "                      rank=9, tensor_func='tensorly'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing tensor...Done.\n",
      "Decomposing tensor...Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.tensor_decomposer.tensorDecomposer.TensorDecomposer at 0x131263390>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_9.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x131238c50>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_9.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing default classification model (standard scaled logistic regression)\n"
     ]
    }
   ],
   "source": [
    "clf_tensor_9 = BoWClassifier(obj_type=\"conversation\", vector_name='tensor_factor', \n",
    "                             labeller=lambda convo: convo.meta['grown2'],\n",
    "                clf_feat_name='tensor-pred', clf_prob_feat_name='tensor-pred-score'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n",
      "[0.84       0.85333333 0.85       0.86166667 0.845     ]\n"
     ]
    }
   ],
   "source": [
    "res = clf_tensor_9.evaluate_with_cv(corpus, cv=KFold(n_splits=5, shuffle=True))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: class information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for generated data\n",
    "for idx, convo in enumerate(corpus.iter_conversations()):\n",
    "    convo.meta['class1'] = int((idx / 1000) < 1)\n",
    "    convo.meta['class2'] = int(1 <= (idx / 1000) < 2)\n",
    "    convo.meta['class3'] = int(idx/1000 >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_base = Classifier(obj_type=\"conversation\", pred_feats=['class1', 'class2', 'class3'], \n",
    "                 labeller=lambda convo: convo.meta['grown2'],\n",
    "                clf_feat_name='base-pred', clf_prob_feat_name='base-pred-score'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9690000000000001"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(clf_base.evaluate_with_cv(corpus, cv=KFold(n_splits=5, shuffle=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in corpus.iter_conversations():\n",
    "    convo.meta['concat'] = dict()\n",
    "    for idx in range(2, 20+1):\n",
    "        d = convo.meta['hyperconvo-{}'.format(idx)].copy()\n",
    "        convo.meta['concat'].update({k+\"_\"+str(idx): v for k, v in d.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2660"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.random_conversation().meta['concat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data = dict()\n",
    "for convo in corpus.iter_conversations():\n",
    "    concat_data[convo.id] = convo.meta['concat']\n",
    "concat_df = pd.DataFrame(concat_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(pd.isnull(concat_df))) # NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_vals = concat_df.values.astype('float64')\n",
    "concat_vals_std = StandardScaler().fit_transform(concat_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: PCA-3[Hyperconvo-2 to Hyperconvo-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for convo in corpus.iter_conversations():\n",
    "    y.append(int(convo.meta['grown2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = concat_vals_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 2996 2997 2999]\n",
      "[   0    1    2 ... 2997 2998 2999]\n",
      "[   0    1    2 ... 2997 2998 2999]\n",
      "[   1    3    4 ... 2995 2996 2998]\n",
      "[   0    2    3 ... 2997 2998 2999]\n"
     ]
    }
   ],
   "source": [
    "pca_3 = PCA(n_components=3)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "acc = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(train_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_pca = pca_3.fit_transform(X_train)\n",
    "    X_test_pca = pca_3.transform(X_test)\n",
    "    clf = svm.SVC(C=0.02, kernel='linear', probability=True)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    acc.append(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6876666666666666\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: PCA-9[Hyperconvo-2 to Hyperconvo-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_9 = PCA(n_components=9)\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "acc_9 = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_pca = pca_9.fit_transform(X_train)\n",
    "    X_test_pca = pca_9.transform(X_test)\n",
    "    clf = svm.SVC(C=0.02, kernel='linear', probability=True)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    acc_9.append(np.mean(y_pred == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7603333333333333\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc_9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark: average[Hyperconvo-2 to Hyperconvo-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "convo_to_avg = dict()\n",
    "for convo in corpus.iter_conversations():\n",
    "    avg_dict = defaultdict(int)\n",
    "    for idx in range(2, 20+1):\n",
    "        d = convo.meta['hyperconvo-{}'.format(idx)]\n",
    "        for k, v in d.items():\n",
    "            avg_dict[k] += v\n",
    "    convo_to_avg[convo.id] = avg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo_id, avg_dict in convo_to_avg.items():\n",
    "    corpus.get_conversation(convo_id).meta['avg'] = dict(avg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_avg = Classifier(obj_type=\"conversation\", pred_feats=['avg'], \n",
    "                 labeller=lambda convo: convo.meta['grown2']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "res = clf_avg.evaluate_with_cv(corpus, cv=KFold(n_splits=5, shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83833333 0.77833333 0.83       0.79833333 0.8       ]\n",
      "0.8089999999999999\n"
     ]
    }
   ],
   "source": [
    "print(res)\n",
    "print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6233"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 40\n",
      "Number of Utterances: 375000\n",
      "Number of Conversations: 15000\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperconvo-20 + TCA (rank 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in corpus.iter_conversations():\n",
    "    convo.meta['tensor_dict'] = {idx: v for idx, v in enumerate(convo.meta['tensor_factor'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_all = Classifier(obj_type=\"conversation\", pred_feats=['hyperconvo-20', 'tensor_dict'], labeller=lambda convo: convo.meta['grown'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "res = clf_all.evaluate_with_cv(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8207333333333333"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperconvo-20 + TCA (rank 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in corpus.iter_conversations():\n",
    "    convo.meta['tensor_dict3'] = {idx: v for idx, v in enumerate(convo.meta['tensor_rank3'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_all_3 = Classifier(obj_type=\"conversation\", pred_feats=['hyperconvo-15', 'tensor_dict3'], labeller=lambda convo: convo.meta['grown'],\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "Running a cross-validated evaluation...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7333333333333334"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = clf_all_3.evaluate_with_cv(corpus)\n",
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
