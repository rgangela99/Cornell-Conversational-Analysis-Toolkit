{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_dir = '/sauna/fake-news'\n",
    "# politics_dir = '/sauna/reddit_201810_raw/corpus/pokemontrades_banlist~-~politics/politics'\n",
    "reddit_dir = '/sauna/fake-news/reddit-corpus'\n",
    "donald_corpus = '/sauna/reddit_201810_raw/corpus/TheTwoBeerQueers~-~The_Donald/The_Donald/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(filename=reddit_dir)\n",
    "# corpus = Corpus(filename=os.path.join(fake_news_dir, 'donald_basic_predictive_valid_convos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = corpus.utterance_threads(include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 10 comments in each thread\n",
    "thread_pfxs = corpus.utterance_threads(prefix_len=5, include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "thread_roots_by_self_post = defaultdict(list)\n",
    "for top_level_comment, thread in threads.items():\n",
    "    if len(thread) < 5: continue\n",
    "    rt = thread[next(iter(thread))].root\n",
    "    thread_roots_by_self_post[rt].append(top_level_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thread_depth(utts): # List of utts\n",
    "    depth = defaultdict(int)\n",
    "    for utt in utts:\n",
    "        depth[utt.id] = depth[utt.reply_to] + 1\n",
    "    return max(depth.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thread_width(utts): # List of utts\n",
    "    width = defaultdict(int)\n",
    "    for utt in utts:\n",
    "        width[utt.reply_to] += 1\n",
    "    return max(width.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interaction_specificity(utts):\n",
    "    utts = list(utts)\n",
    "    return get_thread_depth(utts) / get_thread_width(utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first generate positive and negative examples based on task\n",
    "import random\n",
    "def generate_pos_neg(task: str, post_to_thread_obj, threads, thread_pfxs):\n",
    "    pos, neg = [], []\n",
    "    if task == \"comment-growth\":\n",
    "        for post_id, thread_roots in post_to_thread_obj.items():\n",
    "            has_pos = [root for root in thread_roots if len(threads[root]) >= 15]\n",
    "            has_neg = [root for root in thread_roots if len(threads[root]) == 10]\n",
    "            \n",
    "            if has_pos and has_neg:\n",
    "                pos.append(random.choice(has_pos))\n",
    "                neg.append(random.choice(has_neg))\n",
    "    elif task == \"commenter-growth\":\n",
    "        for post_id, thread_roots in post_to_thread_obj.items():\n",
    "            has_pos, has_neg = [], []\n",
    "            for root in thread_roots:\n",
    "                if len(set(c.user.name for c in threads[root].values())) >= \\\n",
    "                    len(set(c.user.name for c in thread_pfxs[root].values())) * 2:\n",
    "                    has_pos.append(root)\n",
    "                elif len(set(c.user.name for c in threads[root].values())) == \\\n",
    "                    len(set(c.user.name for c in thread_pfxs[root].values())):\n",
    "                    has_neg.append(root)\n",
    "            if has_pos and has_neg:\n",
    "                pos.append(random.choice(has_pos))\n",
    "                neg.append(random.choice(has_neg))\n",
    "    elif task == \"graph-depth-growth\":\n",
    "        for post_id, thread_ids in post_to_thread_obj.items():\n",
    "            has_pos, has_neg = [], []\n",
    "            for thread_id in thread_ids:\n",
    "                if len(threads[thread_id]) >= 20:\n",
    "                    if get_thread_depth(threads[thread_id].values()) >= \\\n",
    "                        get_thread_depth(thread_pfxs[thread_id].values()) * 2:\n",
    "                        has_pos.append(thread_id)\n",
    "                    else:\n",
    "                        has_neg.append(thread_id)\n",
    "            if has_pos and has_neg:\n",
    "                pos.append(random.choice(has_pos))\n",
    "                neg.append(random.choice(has_neg))   \n",
    "    elif task == \"graph-width-growth\":\n",
    "        for post_id, thread_ids in post_to_thread_obj.items():\n",
    "            has_pos, has_neg = [], []\n",
    "            for thread_id in thread_ids:\n",
    "                if len(threads[thread_id]) >= 20:\n",
    "                    if get_thread_width(threads[thread_id].values()) >= \\\n",
    "                        get_thread_width(thread_pfxs[thread_id].values()) * 2:\n",
    "                        has_pos.append(thread_id)\n",
    "                    else:\n",
    "                        has_neg.append(thread_id)\n",
    "            if has_pos and has_neg:\n",
    "                pos.append(random.choice(has_pos))\n",
    "                neg.append(random.choice(has_neg)) \n",
    "    elif task == 'interaction-specificity':\n",
    "        for post_id, thread_ids in post_to_thread_obj.items():\n",
    "            has_pos, has_neg = [], []\n",
    "            for thread_id in thread_ids:\n",
    "                if len(threads[thread_id]) >= 20:\n",
    "                    if get_interaction_specificity(threads[thread_id].values()) >= \\\n",
    "                        get_interaction_specificity(thread_pfxs[thread_id].values()) * 1.8:\n",
    "                        has_pos.append(thread_id)\n",
    "                    else:\n",
    "                        has_neg.append(thread_id)\n",
    "            if has_pos and has_neg:\n",
    "                pos.append(random.choice(has_pos))\n",
    "                neg.append(random.choice(has_neg)) \n",
    "    print(\"- {} positive, {} negative pts for {} task\".format(len(pos), len(neg), task))\n",
    "    \n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1827 positive, 1827 negative pts for comment-growth task\n"
     ]
    }
   ],
   "source": [
    "pos_comment_growth, neg_comment_growth = generate_pos_neg(\"comment-growth\", \n",
    "                                                          thread_roots_by_self_post,\n",
    "                                                          threads,\n",
    "                                                          thread_pfxs\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 769 positive, 769 negative pts for commenter-growth task\n"
     ]
    }
   ],
   "source": [
    "pos_commenter_growth, neg_commenter_growth = generate_pos_neg(\"commenter-growth\", \n",
    "                                                          thread_roots_by_self_post,\n",
    "                                                          threads,\n",
    "                                                          thread_pfxs\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 626 positive, 626 negative pts for graph-depth-growth task\n"
     ]
    }
   ],
   "source": [
    "pos_depth_growth, neg_depth_growth = generate_pos_neg(\"graph-depth-growth\", \n",
    "                                                          thread_roots_by_self_post,\n",
    "                                                          threads,\n",
    "                                                          thread_pfxs\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 619 positive, 619 negative pts for graph-width-growth task\n"
     ]
    }
   ],
   "source": [
    "pos_width_growth, neg_width_growth = generate_pos_neg(\"graph-width-growth\", \n",
    "                                                          thread_roots_by_self_post,\n",
    "                                                          threads,\n",
    "                                                          thread_pfxs\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 631 positive, 631 negative pts for interaction-specificity task\n"
     ]
    }
   ],
   "source": [
    "pos_int_spec, neg_int_spec = generate_pos_neg(\"interaction-specificity\",\n",
    "                                              thread_roots_by_self_post,\n",
    "                                                          threads,\n",
    "                                                          thread_pfxs\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('thread_ids_growth.json', 'w') as f:\n",
    "#     ids = {\"pos-comment-growth\": pos_comment_growth,\n",
    "#            \"neg-comment-growth\": neg_comment_growth,\n",
    "#            \"pos-commenter-growth\": pos_commenter_growth,\n",
    "#            \"neg-commenter-growth\": neg_commenter_growth\n",
    "#           }\n",
    "#     json.dump(ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('thread_ids_growth.json', 'r') as f:\n",
    "#     ids = json.load(f)\n",
    "    \n",
    "# pos_comment_growth = ids['pos-comment-growth']\n",
    "# neg_comment_growth = ids['neg-comment-growth']\n",
    "# pos_commenter_growth = ids['pos-commenter-growth']\n",
    "# neg_commenter_growth = ids['neg-commenter-growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_to_convo = {thread_id: convo_id for convo_id, thread_ids in thread_roots_by_self_post.items() for thread_id in thread_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "commenter_growth_convos = set()\n",
    "for thread_id in pos_commenter_growth:\n",
    "    commenter_growth_convos.add(thread_to_convo[thread_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_growth_convos = set()\n",
    "for thread_id in pos_comment_growth:\n",
    "    comment_growth_convos.add(thread_to_convo[thread_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_growth_convos = set()\n",
    "for thread_id in pos_depth_growth:\n",
    "    depth_growth_convos.add(thread_to_convo[thread_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_growth_convos = set()\n",
    "for thread_id in pos_width_growth:\n",
    "    width_growth_convos.add(thread_to_convo[thread_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_convos = comment_growth_convos.union(commenter_growth_convos).union(depth_growth_convos).union(width_growth_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.filter_conversations_by(lambda convo: convo.id in paired_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus.dump('donald_basic_predict_2', base_path=fake_news_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = convokit.HyperConvo(prefix_len=5, min_thread_len=5, include_root=False)\n",
    "orig_hc = convokit.HyperConvo_0(prefix_len=5, min_thread_len=5, include_root=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo_orig/hyperconvo_o.py:177: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \"norm.max\": lambda l: np.max(l) / np.sum(l),\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo_orig/hyperconvo_o.py:182: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan,\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/caleb/miniconda/envs/venv/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2614: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pk = 1.0*pk / np.sum(pk, axis=0)\n",
      "/home/caleb/Cornell-Conversational-Analysis-Toolkit/convokit/hyperconvo_orig/hyperconvo_o.py:189: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if len(l) > 1 else np.nan\n"
     ]
    }
   ],
   "source": [
    "hyperconvo_feats = orig_hc.retrieve_feats(corpus, prefix_len=10, min_thread_len=10, include_root=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_feats = hc.retrieve_feats(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_feats_df = pd.DataFrame.from_dict(motif_feats, orient='index')\n",
    "motif_feat_names = list(motif_feats_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperconv_df = pd.DataFrame.from_dict(hyperconvo_feats, orient='index')\n",
    "hyperconv_feat_names = list(hyperconv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_stats = hc.retrieve_motif_pathway_stats(corpus)\n",
    "path_stats_df = pd.DataFrame.from_dict(path_stats, orient='index')\n",
    "columns = ['PATH-'+', '.join(filter(lambda x: type(x) == str, col)).strip() for col in path_stats_df.columns.values]\n",
    "path_stats_df.columns = columns\n",
    "\n",
    "path_stats_enum_df = pd.DataFrame()\n",
    "\n",
    "for path_stat in columns:\n",
    "    path_stats_enum_df['is-present[{}]'.format(path_stat)] = path_stats_df[path_stat] > 0\n",
    "    path_stats_enum_df['count[{}]'.format(path_stat)] = path_stats_df[path_stat]\n",
    "\n",
    "path_feat_names = list(path_stats_enum_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_users(thread):\n",
    "    return len(set(utt.user.name for utt in thread.values()))\n",
    "\n",
    "thread_to_usercount = dict()\n",
    "for thread_id in thread_pfxs:\n",
    "    if len(thread_pfxs[thread_id]) < 10: continue\n",
    "    thread_to_usercount[thread_id] = {\"num_users\": get_num_users(thread_pfxs[thread_id])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users_df = pd.DataFrame.from_dict(thread_to_usercount, orient='index')\n",
    "num_users_feat = ['num_users']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = pd.concat([hyperconv_df, motif_feats_df, path_stats_enum_df, num_users_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threads = {k: v for k, v in corpus.utterance_threads(include_root=False).items() if k in valid_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the first 10 comments in each thread\n",
    "# thread_pfxs = {k: v for k, v in corpus.utterance_threads(prefix_len=10, include_root=False).items() if k in valid_threads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = feats_df.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_df = feats_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "for task in [\"comment-growth\", \"commenter-growth\", \"graph-depth-growth\", \"graph-width-growth\", \"interaction-specificity\"]: #, \"post-deleted\", \"user-deleted\"\n",
    "    print(\"TASK: {}\\n\".format(task))\n",
    "    \n",
    "    if task == \"comment-growth\":\n",
    "        pos, neg = pos_comment_growth, neg_comment_growth\n",
    "    elif task == \"commenter-growth\":\n",
    "        pos, neg = pos_commenter_growth, neg_commenter_growth\n",
    "    elif task == \"graph-depth-growth\":\n",
    "        pos, neg = pos_depth_growth, neg_depth_growth\n",
    "    elif task == \"graph-width-growth\":\n",
    "        pos, neg = pos_width_growth, neg_width_growth\n",
    "    elif task == \"interaction-specificity\":\n",
    "        pos, neg = pos_int_spec, neg_int_spec\n",
    "        \n",
    "#     pos, neg = generate_pos_neg(task, thread_roots_by_self_post, threads, thread_pfxs)\n",
    "    for feature_set, name in [(hyperconv_feat_names, \"hyperconvo\"),\n",
    "                        (motif_feat_names, \"motif\"),\n",
    "                        (path_feat_names, \"motifpaths\"),\n",
    "                        (motif_feat_names + path_feat_names, \"motif-all\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names, \"hyperconv-motif\"),\n",
    "                        (hyperconv_feat_names + path_feat_names, \"hyperconv-paths\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names + path_feat_names, \"hyperconvo-motifall\"),\n",
    "                        (num_users_feat, \"usercount\"),\n",
    "#                         (hyperconv_feat_names + num_users_feat, \"hyperconv-usercount\"),\n",
    "#                         (motif_feat_names + num_users_feat, \"motif-usercount\"),\n",
    "#                         (path_feat_names + num_users_feat, \"motifpaths-usercount\"),\n",
    "#                         (motif_feat_names + path_feat_names + num_users_feat, \"motifsall+usercount\"),\n",
    "                        (hyperconv_feat_names + motif_feat_names + path_feat_names + num_users_feat, \"hyperconvo-motifall+usercount\"),\n",
    "                       ]:\n",
    "        clf = Pipeline([(\"standardScaler\", StandardScaler()), (\"logreg\", LogisticRegression(solver='liblinear'))])      \n",
    "        loo = LeaveOneOut()\n",
    "        pp = convokit.PairedPrediction()\n",
    "        X, y = pp._generate_paired_X_y(feats_df[feature_set], pos, neg)\n",
    "\n",
    "#         clf.fit(X, y)\n",
    "#         clf.score(X, y)\n",
    "#         print(X.shape)\n",
    "#         print(X[0])\n",
    "#         print(y.shape)\n",
    "        scores = cross_val_score(clf, X, y, cv=loo)\n",
    "        print(\"- {}, cv_accuracy: {:.4f}\".format(name, scores.mean()))\n",
    "\n",
    "\n",
    "#         print(\"Feature set: {}\".format(name))\n",
    "#         pp.fit_predict(feats_df[feature_set], pos, neg, test_size=0.2)\n",
    "#         pp.print_extreme_coefs(feature_set, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
